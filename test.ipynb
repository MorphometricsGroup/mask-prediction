{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import albumentations as A\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list = glob(os.path.normpath('./saved_images/*'))\n",
    "\n",
    "# Set variables for model\n",
    "DATA_DIR = img_path_list\n",
    "ENCODER = 'resnet34'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['background', 'soybean', 'stake']\n",
    "ACTIVATION = 'softmax2d'\n",
    "DEVICE = 'cpu' # cuda or cpu\n",
    "\n",
    "model_parameters_path = './best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset for inference  \n",
    "class Dataset(BaseDataset):\n",
    "    def __init__(self, data_dir, augmentation=None, preprocessing=None):\n",
    "        self.image_paths = data_dir\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.image_paths[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentation is not None:\n",
    "            sample = self.augmentation(image=image)\n",
    "            image = sample['image']\n",
    "        \n",
    "        transform = A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], p=1.0)\n",
    "        sample = transform(image=image)\n",
    "        image = sample['image']\n",
    "        \n",
    "        if self.preprocessing is not None:\n",
    "            sample = self.preprocessing(image=image)\n",
    "            image = sample['image']\n",
    "            \n",
    "        image = torch.from_numpy(image) \n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model\n",
    "def prepare_model():\n",
    "        # Define model\n",
    "        model = smp.Unet(\n",
    "        encoder_name=ENCODER,\n",
    "        encoder_weights=ENCODER_WEIGHTS,\n",
    "        in_channels=3,\n",
    "        classes=len(CLASSES),\n",
    "        activation=ACTIVATION\n",
    "        )\n",
    "        \n",
    "        model.to(DEVICE)\n",
    "        \n",
    "        # Install trained parameters in model\n",
    "        model.load_state_dict(torch.load(model_parameters_path))\n",
    "        model.eval()\n",
    "        \n",
    "        return model\n",
    "\n",
    "# Create dataset\n",
    "def create_dataset():\n",
    "        # Define augmentation for inference\n",
    "        def get_inference_augmentation():\n",
    "            transform = A.Compose([\n",
    "                A.Resize(width=512, height=512, p=1.0)\n",
    "            ], p=1.0)\n",
    "            return transform\n",
    "    \n",
    "        def to_tensor(x, **kwargs):\n",
    "            return x.transpose(2, 0, 1).astype('float32') \n",
    "\n",
    "        def get_preprocessing(preprocessing_fn):\n",
    "            _transform = A.Compose([\n",
    "                A.Lambda(image=preprocessing_fn, p=1.0),\n",
    "                A.Lambda(image=to_tensor, mask=to_tensor, p=1.0)\n",
    "            ], p=1.0)\n",
    "            return _transform\n",
    "                \n",
    "        # Set pretrained parameters\n",
    "        preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "        \n",
    "        # Create dataset\n",
    "        dataset = Dataset(\n",
    "            data_dir=DATA_DIR, \n",
    "            augmentation=get_inference_augmentation(),\n",
    "            preprocessing=get_preprocessing(preprocessing_fn)\n",
    "        )\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model()\n",
    "dataset = create_dataset()\n",
    "\n",
    "mask_folder_path = './test_output_masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.1257, -2.1272, -2.1272,  ..., -2.1278, -2.1266, -2.1269],\n",
      "          [-2.1266, -2.1248, -2.1260,  ..., -2.1257, -2.1266, -2.1263],\n",
      "          [-2.1266, -2.1260, -2.1251,  ..., -2.1269, -2.1269, -2.1275],\n",
      "          ...,\n",
      "          [-2.1307, -2.1316, -2.1304,  ..., -2.1287, -2.1284, -2.1290],\n",
      "          [-2.1292, -2.1292, -2.1292,  ..., -2.1284, -2.1295, -2.1281],\n",
      "          [-2.1292, -2.1292, -2.1295,  ..., -2.1295, -2.1295, -2.1287]],\n",
      "\n",
      "         [[-2.0174, -2.0165, -2.0174,  ..., -2.0196, -2.0202, -2.0205],\n",
      "          [-2.0171, -2.0165, -2.0177,  ..., -2.0196, -2.0211, -2.0208],\n",
      "          [-2.0168, -2.0177, -2.0168,  ..., -2.0205, -2.0202, -2.0205],\n",
      "          ...,\n",
      "          [-2.0214, -2.0217, -2.0214,  ..., -2.0419, -2.0410, -2.0428],\n",
      "          [-2.0217, -2.0214, -2.0217,  ..., -2.0410, -2.0425, -2.0422],\n",
      "          [-2.0223, -2.0223, -2.0226,  ..., -2.0428, -2.0425, -2.0422]],\n",
      "\n",
      "         [[-1.7724, -1.7724, -1.7721,  ..., -1.7751, -1.7754, -1.7757],\n",
      "          [-1.7724, -1.7721, -1.7724,  ..., -1.7754, -1.7764, -1.7764],\n",
      "          [-1.7715, -1.7721, -1.7709,  ..., -1.7757, -1.7754, -1.7751],\n",
      "          ...,\n",
      "          [-1.7748, -1.7754, -1.7751,  ..., -1.8061, -1.8052, -1.8058],\n",
      "          [-1.7748, -1.7745, -1.7751,  ..., -1.8052, -1.8067, -1.8052],\n",
      "          [-1.7754, -1.7754, -1.7754,  ..., -1.8061, -1.8067, -1.8064]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▌                                     | 1/6 [00:00<00:03,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.1284, -2.1269, -2.1284,  ..., -2.1204, -2.1222, -2.1207],\n",
      "          [-2.1295, -2.1290, -2.1298,  ..., -2.1213, -2.1222, -2.1219],\n",
      "          [-2.1281, -2.1284, -2.1284,  ..., -2.1222, -2.1222, -2.1234],\n",
      "          ...,\n",
      "          [-2.1284, -2.1290, -2.1295,  ..., -2.1372, -2.1383, -2.1386],\n",
      "          [-2.1295, -2.1298, -2.1298,  ..., -2.1366, -2.1369, -2.1375],\n",
      "          [-2.1295, -2.1290, -2.1295,  ..., -2.1366, -2.1372, -2.1378]],\n",
      "\n",
      "         [[-2.0199, -2.0196, -2.0214,  ..., -2.0196, -2.0211, -2.0199],\n",
      "          [-2.0202, -2.0205, -2.0202,  ..., -2.0205, -2.0208, -2.0202],\n",
      "          [-2.0205, -2.0208, -2.0205,  ..., -2.0208, -2.0208, -2.0208],\n",
      "          ...,\n",
      "          [-2.0199, -2.0202, -2.0208,  ..., -2.0524, -2.0520, -2.0520],\n",
      "          [-2.0196, -2.0199, -2.0214,  ..., -2.0520, -2.0517, -2.0511],\n",
      "          [-2.0196, -2.0196, -2.0208,  ..., -2.0517, -2.0527, -2.0527]],\n",
      "\n",
      "         [[-1.7739, -1.7733, -1.7745,  ..., -1.7742, -1.7751, -1.7739],\n",
      "          [-1.7736, -1.7745, -1.7742,  ..., -1.7751, -1.7754, -1.7751],\n",
      "          [-1.7736, -1.7751, -1.7754,  ..., -1.7754, -1.7754, -1.7754],\n",
      "          ...,\n",
      "          [-1.7748, -1.7748, -1.7757,  ..., -1.8155, -1.8158, -1.8155],\n",
      "          [-1.7748, -1.7748, -1.7754,  ..., -1.8152, -1.8152, -1.8152],\n",
      "          [-1.7751, -1.7748, -1.7757,  ..., -1.8149, -1.8158, -1.8161]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████                              | 2/6 [00:01<00:02,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.1369, -2.1372, -2.1369,  ..., -2.1507, -2.1489, -2.1471],\n",
      "          [-2.1372, -2.1366, -2.1380,  ..., -2.1492, -2.1489, -2.1471],\n",
      "          [-2.1372, -2.1369, -2.1375,  ..., -2.1501, -2.1477, -2.1477],\n",
      "          ...,\n",
      "          [-2.1319, -2.1313, -2.1331,  ..., -2.1339, -2.1325, -2.1328],\n",
      "          [-2.1319, -2.1316, -2.1325,  ..., -2.1336, -2.1328, -2.1336],\n",
      "          [-2.1301, -2.1307, -2.1328,  ..., -2.1363, -2.1339, -2.1351]],\n",
      "\n",
      "         [[-2.0530, -2.0533, -2.0527,  ..., -2.0545, -2.0542, -2.0524],\n",
      "          [-2.0533, -2.0533, -2.0530,  ..., -2.0545, -2.0545, -2.0511],\n",
      "          [-2.0530, -2.0520, -2.0517,  ..., -2.0554, -2.0527, -2.0514],\n",
      "          ...,\n",
      "          [-2.0294, -2.0309, -2.0315,  ..., -2.0245, -2.0251, -2.0257],\n",
      "          [-2.0294, -2.0284, -2.0288,  ..., -2.0263, -2.0260, -2.0260],\n",
      "          [-2.0300, -2.0297, -2.0284,  ..., -2.0266, -2.0254, -2.0245]],\n",
      "\n",
      "         [[-1.8165, -1.8168, -1.8161,  ..., -1.8171, -1.8155, -1.8143],\n",
      "          [-1.8168, -1.8165, -1.8174,  ..., -1.8155, -1.8143, -1.8110],\n",
      "          [-1.8165, -1.8158, -1.8158,  ..., -1.8168, -1.8149, -1.8128],\n",
      "          ...,\n",
      "          [-1.7855, -1.7858, -1.7861,  ..., -1.7818, -1.7812, -1.7809],\n",
      "          [-1.7849, -1.7849, -1.7846,  ..., -1.7821, -1.7821, -1.7812],\n",
      "          [-1.7852, -1.7852, -1.7852,  ..., -1.7827, -1.7812, -1.7812]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 3/6 [00:02<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.1290, -2.1284, -2.1284,  ..., -2.1196, -2.1178, -2.1196],\n",
      "          [-2.1272, -2.1290, -2.1290,  ..., -2.1196, -2.1187, -2.1196],\n",
      "          [-2.1287, -2.1287, -2.1304,  ..., -2.1190, -2.1199, -2.1187],\n",
      "          ...,\n",
      "          [-2.1290, -2.1275, -2.1281,  ..., -2.1269, -2.1272, -2.1272],\n",
      "          [-2.1269, -2.1263, -2.1281,  ..., -2.1287, -2.1281, -2.1278],\n",
      "          [-2.1275, -2.1278, -2.1275,  ..., -2.1269, -2.1246, -2.1266]],\n",
      "\n",
      "         [[-2.0217, -2.0214, -2.0211,  ..., -2.0159, -2.0150, -2.0150],\n",
      "          [-2.0196, -2.0205, -2.0217,  ..., -2.0156, -2.0143, -2.0159],\n",
      "          [-2.0208, -2.0214, -2.0196,  ..., -2.0147, -2.0147, -2.0153],\n",
      "          ...,\n",
      "          [-2.0177, -2.0183, -2.0180,  ..., -2.0404, -2.0416, -2.0413],\n",
      "          [-2.0183, -2.0177, -2.0183,  ..., -2.0413, -2.0407, -2.0407],\n",
      "          [-2.0186, -2.0189, -2.0183,  ..., -2.0404, -2.0392, -2.0413]],\n",
      "\n",
      "         [[-1.7748, -1.7754, -1.7757,  ..., -1.7703, -1.7691, -1.7694],\n",
      "          [-1.7745, -1.7748, -1.7767,  ..., -1.7700, -1.7691, -1.7703],\n",
      "          [-1.7748, -1.7767, -1.7757,  ..., -1.7700, -1.7697, -1.7697],\n",
      "          ...,\n",
      "          [-1.7724, -1.7721, -1.7733,  ..., -1.8043, -1.8052, -1.8049],\n",
      "          [-1.7727, -1.7721, -1.7730,  ..., -1.8052, -1.8049, -1.8049],\n",
      "          [-1.7721, -1.7724, -1.7721,  ..., -1.8046, -1.8031, -1.8049]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████               | 4/6 [00:02<00:01,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.1301, -2.1301, -2.1301,  ..., -2.1375, -2.1383, -2.1366],\n",
      "          [-2.1325, -2.1307, -2.1322,  ..., -2.1378, -2.1380, -2.1369],\n",
      "          [-2.1301, -2.1304, -2.1304,  ..., -2.1386, -2.1380, -2.1383],\n",
      "          ...,\n",
      "          [-2.1298, -2.1284, -2.1290,  ..., -2.0861, -2.0858, -2.0856],\n",
      "          [-2.1292, -2.1281, -2.1307,  ..., -2.0853, -2.0850, -2.0864],\n",
      "          [-2.1287, -2.1298, -2.1298,  ..., -2.0856, -2.0861, -2.0858]],\n",
      "\n",
      "         [[-2.0254, -2.0254, -2.0235,  ..., -2.0309, -2.0306, -2.0288],\n",
      "          [-2.0242, -2.0235, -2.0254,  ..., -2.0309, -2.0294, -2.0300],\n",
      "          [-2.0245, -2.0242, -2.0223,  ..., -2.0309, -2.0297, -2.0288],\n",
      "          ...,\n",
      "          [-2.0232, -2.0223, -2.0214,  ..., -2.0002, -2.0002, -2.0002],\n",
      "          [-2.0226, -2.0208, -2.0211,  ..., -1.9999, -2.0006, -2.0009],\n",
      "          [-2.0232, -2.0229, -2.0223,  ..., -2.0002, -2.0009, -2.0006]],\n",
      "\n",
      "         [[-1.7785, -1.7785, -1.7767,  ..., -1.7839, -1.7839, -1.7836],\n",
      "          [-1.7779, -1.7773, -1.7794,  ..., -1.7843, -1.7839, -1.7839],\n",
      "          [-1.7773, -1.7794, -1.7773,  ..., -1.7855, -1.7855, -1.7846],\n",
      "          ...,\n",
      "          [-1.7773, -1.7764, -1.7773,  ..., -1.7654, -1.7657, -1.7657],\n",
      "          [-1.7779, -1.7773, -1.7776,  ..., -1.7648, -1.7648, -1.7651],\n",
      "          [-1.7779, -1.7785, -1.7782,  ..., -1.7648, -1.7657, -1.7654]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████▌       | 5/6 [00:03<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.1292, -2.1284, -2.1284,  ..., -2.1345, -2.1339, -2.1334],\n",
      "          [-2.1284, -2.1284, -2.1272,  ..., -2.1351, -2.1366, -2.1336],\n",
      "          [-2.1278, -2.1269, -2.1281,  ..., -2.1351, -2.1348, -2.1360],\n",
      "          ...,\n",
      "          [-2.1336, -2.1336, -2.1336,  ..., -2.1322, -2.1307, -2.1325],\n",
      "          [-2.1345, -2.1348, -2.1339,  ..., -2.1304, -2.1304, -2.1331],\n",
      "          [-2.1336, -2.1342, -2.1336,  ..., -2.1319, -2.1319, -2.1313]],\n",
      "\n",
      "         [[-2.0235, -2.0242, -2.0238,  ..., -2.0254, -2.0257, -2.0245],\n",
      "          [-2.0245, -2.0242, -2.0232,  ..., -2.0251, -2.0254, -2.0254],\n",
      "          [-2.0245, -2.0242, -2.0238,  ..., -2.0263, -2.0248, -2.0260],\n",
      "          ...,\n",
      "          [-2.0269, -2.0266, -2.0263,  ..., -2.0211, -2.0205, -2.0211],\n",
      "          [-2.0272, -2.0269, -2.0269,  ..., -2.0205, -2.0205, -2.0211],\n",
      "          [-2.0275, -2.0272, -2.0272,  ..., -2.0220, -2.0220, -2.0217]],\n",
      "\n",
      "         [[-1.7788, -1.7788, -1.7794,  ..., -1.7800, -1.7800, -1.7797],\n",
      "          [-1.7791, -1.7788, -1.7785,  ..., -1.7794, -1.7803, -1.7803],\n",
      "          [-1.7794, -1.7800, -1.7791,  ..., -1.7800, -1.7794, -1.7806],\n",
      "          ...,\n",
      "          [-1.7800, -1.7806, -1.7803,  ..., -1.7754, -1.7748, -1.7757],\n",
      "          [-1.7806, -1.7806, -1.7809,  ..., -1.7745, -1.7748, -1.7761],\n",
      "          [-1.7806, -1.7812, -1.7809,  ..., -1.7757, -1.7761, -1.7764]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [00:04<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "def inference(model, dataset):\n",
    "    def one_hot_function(pr_mask):\n",
    "        max_index_number = pr_mask.argmax(axis=0) \n",
    "        for i in range(len(pr_mask)):\n",
    "            one_hot_vector = (max_index_number == i) \n",
    "            pr_mask[i] = one_hot_vector\n",
    "        return pr_mask\n",
    "    \n",
    "    for i in tqdm(range(len(dataset)), ncols=80):\n",
    "        image = dataset[i]\n",
    "        x_tensor = image.to(DEVICE).unsqueeze(0)\n",
    "        pr_mask = model.predict(x_tensor)\n",
    "        pr_mask = pr_mask.squeeze().cpu().numpy()\n",
    "        pr_mask = one_hot_function(pr_mask)\n",
    "        pr_mask = pr_mask[CLASSES.index('soybean')] # Extract only soybean\n",
    "        image_path = DATA_DIR[i]\n",
    "        assert dataset.image_paths[i] == image_path, \"Not match pathes\"\n",
    "        raw_image = cv2.imread(image_path)\n",
    "        height, width = raw_image.shape[:2]\n",
    "        pr_mask = A.resize(pr_mask, height, width)\n",
    "        pr_mask = pr_mask * 255\n",
    "        pr_mask_path = os.path.normpath(os.path.join(mask_folder_path, os.path.basename(DATA_DIR[i]).split('.')[0]+'.png')) # Save masks as PNG format\n",
    "        cv2.imwrite(pr_mask_path, pr_mask)\n",
    "\n",
    "inference(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "339b61edfe2862de78527346fab7b54ea336c8710f2c1713032939182b3058a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
